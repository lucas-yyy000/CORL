{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from dataclasses import asdict, dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import yaml\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from tensordict import MemoryMappedTensor, TensorDict\n",
    "\n",
    "from actor_utils import ActorNet\n",
    "from utils import *\n",
    "# from bc_debug import ActorNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained model. ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = \"/home/yixuany/workspace/CORL/output\"\n",
    "run_name = \"BC-evasion-v2-multimodal-fdfb354f\"\n",
    "model_dict = torch.load(os.path.join(checkpoints_path, run_name, \"checkpoint_1550000.pt\"))\n",
    "# model_dict = torch.load(os.path.join(checkpoints_path, \"checkpoint_1550000.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(checkpoints_path, run_name, \"config.yaml\"),\"r\") as file_object:\n",
    "    config = yaml.load(file_object,Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment parameters.\n",
    "img_size = config['env']['img_size']\n",
    "time_max = config['env']['max_time_step']\n",
    "observation_img_size = [1, img_size, img_size]\n",
    "action_dim = config['env']['action_dim']\n",
    "action_space = gym.spaces.Box(low=-1.0, high=1.0, shape=(action_dim,))\n",
    "map_size = config['env']['map_size']\n",
    "if config['env']['observation']['goal_direction_normalized']:\n",
    "    observation_space= gym.spaces.Dict({\"heat_map\": gym.spaces.Box(0, 255, observation_img_size), \n",
    "                            \"goal_direction\": gym.spaces.Box(-1, 1, shape=(2,))})\n",
    "else:\n",
    "    observation_space= gym.spaces.Dict({\"heat_map\": gym.spaces.Box(0, 255, observation_img_size), \n",
    "                            \"goal_direction\": gym.spaces.Box(-map_size / 2.0, map_size / 2.0, shape=(2,))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Actor ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ReLU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ActorNet(\n",
       "  (feature_extractor): FeatureExtractor(\n",
       "    (extractors): ModuleDict(\n",
       "      (goal_direction): Flatten(start_dim=1, end_dim=-1)\n",
       "      (heat_map): NatureCNN(\n",
       "        (cnn): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "          (1): ReLU()\n",
       "          (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "          (3): ReLU()\n",
       "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (5): ReLU()\n",
       "          (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (linear): Sequential(\n",
       "          (0): Linear(in_features=5184, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (policy_net): Sequential(\n",
       "    (0): Linear(in_features=258, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (action_net): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert config['policy']['hidden_act'] == 'Tanh' or config['policy']['hidden_act'] == 'ReLU', \"Currently only support ReLU or Tanh.\"\n",
    "if config['policy']['hidden_act'] == 'Tanh':\n",
    "    actor = ActorNet(observation_space, action_space, config['policy']['actor_net_hidden'], hidden_act=nn.Tanh)\n",
    "if config['policy']['hidden_act'] == 'ReLU':\n",
    "    print(\"Using ReLU.\")\n",
    "    actor = ActorNet(observation_space, action_space, config['policy']['actor_net_hidden'], hidden_act=nn.ReLU)\n",
    "actor.load_state_dict(model_dict['actor'])\n",
    "actor.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load one of the training data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_t = config['env']['delta_t']\n",
    "V = config['env']['V']\n",
    "radar_radius = config['env']['radar_radius']\n",
    "aircraft_detection_range = config['env']['aircraft_detection_range']\n",
    "grid_size=2*aircraft_detection_range/img_size\n",
    "time_scaling = config['env']['observation']['time_scaling']\n",
    "action_rescaling = config['env']['action_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_idx = 1\n",
    "data_path = \"/home/yixuany/workspace/CORL/data/\"\n",
    "episode_dict = np.load(data_path + f'episode_{episode_idx}.npy',allow_pickle='TRUE').item()\n",
    "\n",
    "state_cur = episode_dict['start_state']\n",
    "radar_locs = episode_dict['radar_locations']\n",
    "radar_orientations = episode_dict['radar_orientations']\n",
    "# goal_location = episode_dict['goal_location']\n",
    "goal_location = [1000.0, 1000.0]\n",
    "\n",
    "\n",
    "time_spent = 0\n",
    "time_spent_heat_map = 0\n",
    "trajectory = [state_cur]\n",
    "q_values = []\n",
    "start = time.time()\n",
    "with torch.no_grad():\n",
    "    while np.linalg.norm(state_cur[:2] - goal_location) > config['env']['goal_tolerance']:\n",
    "        if time_spent % 10 == 0:\n",
    "            print(\"Time spent: \", time_spent)\n",
    "        if time_spent > config['env']['max_time_step']:\n",
    "            print(\"Reached time limit.\")\n",
    "            break\n",
    "        hm_start = time.time()\n",
    "        heat_map = get_radar_heat_map(state_cur, radar_locs, img_size,\n",
    "                                           aircraft_detection_range,\n",
    "                                           grid_size, \n",
    "                                           radar_radius)\n",
    "        hm_end = time.time()\n",
    "        time_spent_heat_map += hm_end - hm_start\n",
    "        goal_direction = center_state(state_cur, goal_location) / (map_size / 2.0)\n",
    "        \n",
    "        obs = TensorDict({\n",
    "            'heat_map': torch.from_numpy(heat_map).unsqueeze(dim=0).float(),\n",
    "            'goal_direction': torch.from_numpy(goal_direction).unsqueeze(dim=0).float()\n",
    "        })\n",
    "\n",
    "        u, distribution = actor(obs)\n",
    "        log_prob = distribution.distribution.log_prob(u).squeeze().cpu().detach().numpy()\n",
    "        u = u.squeeze().cpu().detach().numpy()\n",
    "        u = action_rescaling*(u[np.argmax(log_prob)])\n",
    "        state_cur = state_cur + delta_t*np.array([V*np.cos(state_cur[2]), V*np.sin(state_cur[2]), u/V])\n",
    "        time_spent += 1\n",
    "        # print(state_cur)\n",
    "        trajectory.append(state_cur)\n",
    "end = time.time()\n",
    "print(\"Total time steps: \", time_spent)\n",
    "print(\"Total Time: \", end - start)\n",
    "print(\"Time spent on heat map\", time_spent_heat_map)\n",
    "trajectory = np.asarray(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the trajectory generated by student policy. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, ax = plt.subplots()\n",
    "visualiza_radar_config(radar_locs, radar_orientations, radius=radar_radius, xlim=[0, map_size], ylim=[0, map_size])\n",
    "\n",
    "\n",
    "ax.scatter(trajectory[:, 0], trajectory[:, 1], s=10, c='r', alpha=0.3, label='Student')\n",
    "# ax.scatter(episode_dict['state_history'][:, 0], episode_dict['state_history'][:, 1], s=10, c='g', alpha=0.3, label='Expert')\n",
    "ax.scatter(episode_dict['start_state'][0], episode_dict['start_state'][1], s=50, c='g', marker='x', label=\"Start\")\n",
    "ax.scatter(goal_location[0], goal_location[1], s=70, c='g', marker='*', label='Goal')\n",
    "\n",
    "ax.set_xlim(-200, 1.2*map_size)\n",
    "ax.set_ylim(-200, 1.2*map_size)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Debugging: Visualize Heat maps. Visualize the collected training trajectories. ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_size = 100\n",
    "# radar_radius = 100\n",
    "# aircraft_detection_range=100\n",
    "# grid_size=2*aircraft_detection_range/img_size\n",
    "# heat_map = get_radar_heat_map(episode_dict['start_state'], radar_locs, img_size, aircraft_detection_range, grid_size, radar_radius)\n",
    "\n",
    "# plt.close()\n",
    "# plt.imshow(heat_map.squeeze(), cmap='hot', interpolation='nearest', origin=\"lower\")\n",
    "# plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close()\n",
    "# fig, ax = plt.subplots()\n",
    "# visualiza_radar_config(radar_locs, radar_orientations, radius=radar_radius, xlim=[0, map_size], ylim=[0, map_size])\n",
    "for i in range(1000):\n",
    "    episode_idx = i\n",
    "    episode_dict = np.load(data_path + f'episode_{episode_idx}.npy',allow_pickle='TRUE').item()\n",
    "    \n",
    "    if math.hypot(episode_dict['goal_location'][0] - goal_location[0], episode_dict['goal_location'][1] - goal_location[1]) < 5.0:\n",
    "        print(\"Exists similar goal: \",episode_dict['goal_location'] )\n",
    "    # ax.scatter(episode_dict['state_history'][:, 0], episode_dict['state_history'][:, 1], s=1, c='g', alpha=0.3)\n",
    "    # ax.scatter(episode_dict['start_state'][0], episode_dict['start_state'][1], s=50, c='g', marker='x')\n",
    "    # ax.scatter(episode_dict['goal_location'][0], episode_dict['goal_location'][1], s=50, c='g', marker='*')\n",
    "\n",
    "# ax.set_xlim(-200, 1.2*map_size)\n",
    "# ax.set_ylim(-200, 1.2*map_size)\n",
    "# # ax.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
